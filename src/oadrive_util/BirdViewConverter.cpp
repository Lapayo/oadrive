// this is for emacs file handling -*- mode: c++; indent-tabs-mode: nil -*-

// -- BEGIN LICENSE BLOCK ----------------------------------------------
// This program is free software licensed under the CDDL
// (COMMON DEVELOPMENT AND DISTRIBUTION LICENSE Version 1.0).
// You can find a copy of this license in LICENSE in the top
// directory of the source code.
//
// Â© Copyright 2018 FZI Forschungszentrum Informatik, Karlsruhe, Germany
// -- END LICENSE BLOCK ------------------------------------------------

//----------------------------------------------------------------------
/*!\file
 *
 * \author  Peter Zimmer <peter-zimmer@gmx.net>
 * \author  Micha Pfeiffer <ueczz@student.kit.edu>
 * \author  Robin Andlauer <robin.andlauer@student.kit.edu
 * \date    2015-11-24
 * 
 * \author  Simon Roesler <simon.roesler@student.kit.edu>
 * \date    2018
 * 
 * \author  Mark Hueneberg <hueneber@fzi.de>
 * \date    2018
 *
 */
//----------------------------------------------------------------------

#include "BirdViewConverter.h"
#include <iostream>
#include "utilLogging.h"
#include <opencv2/flann/timer.h>

#ifdef USE_CUDA
  #include <opencv2/cudaarithm.hpp>
  #include <opencv2/opencv.hpp>
#endif

using icl_core::logging::endl;
using icl_core::logging::flush;

namespace oadrive
{
namespace util
{
BirdViewConverter::BirdViewConverter() :
        mUndistEnable(false)
{
}


cv::Mat BirdViewConverter::transform(cv::Mat image)
{
  cv::Mat dest;

  // undistortion coefficient not provided for simulation
  if (mUndistEnable)
  {
    cv::remap(image, dest, undistortAndWarpXMapInt, undistortAndWarpYMapInt, cv::INTER_LINEAR);
  }
  else
  {
#ifdef USE_CUDA
    cv::cuda::GpuMat gpuImage(image);
    cv::cuda::GpuMat gpuOutput;
    cv::cuda::GpuMat gpuOutput2;

    cv::cuda::warpPerspective(gpuImage, gpuOutput, mWarpMatrix, gpuImage.size(), cv::INTER_LINEAR,
                              cv::BORDER_CONSTANT);
    cv::cuda::resize(gpuOutput, gpuOutput2, mImgSize);
    gpuOutput2.download(dest);
#else
    cv::warpPerspective(image, dest, mWarpMatrix, mImgSize, cv::INTER_LINEAR, cv::BORDER_CONSTANT);
#endif
  }

  return dest;
}

bool BirdViewConverter::loadConfig(std::string path)
{
  bool success = false;
  cv::FileStorage fs2(path, cv::FileStorage::READ);
  LOGGING_INFO(utilLogger, "try to load File" << path << endl);
  if (fs2.isOpened())
  {
    LOGGING_TRACE(utilLogger, "open calibration file" << endl);
    cv::FileNode nodeCameraMatrix, nodeDistCoeffs, nodewarpMatrix, nodeSize;

    nodewarpMatrix = fs2["warpMatrix"];
    nodeSize = fs2["ImgSize"];
    nodeCameraMatrix = fs2["camera_matrix"];
    nodeDistCoeffs = fs2["distortion_coefficients"];
    if (nodewarpMatrix.empty() || nodeSize.empty())
    {
      LOGGING_ERROR(utilLogger,
                    "can't find warpMatrix or Image Size in Calibration File please check the file"
                            << endl);
      throw ("can't find warpMatrix or Image Size in Calibration File please check the file");
    }
    else
    {
      LOGGING_INFO(utilLogger, "Read  Warp Matrix and Image Size:" << endl);
      fs2["warpMatrix"] >> mWarpMatrix;
      fs2["ImgSize"] >> mImgSize;
      if (!fs2["BirdviewScale"].empty()) {
        fs2["BirdviewScale"] >> mBirdviewScale;
      }
      if (nodeCameraMatrix.empty() || nodeDistCoeffs.empty())
      {
        LOGGING_WARNING(utilLogger,
                        "Can't find camera matrix and or distortion coefficients undistortion is turned off"
                                << endl);
      }
      else
      {
        LOGGING_INFO(utilLogger, "Read Camera Matrix and distortion coefficients" << endl);
        fs2["distortion_coefficients"] >> mDistCoeffs;
        fs2["camera_matrix"] >> mCameraMatrix;
        mUndistEnable = false;
      }
    }

    success = true;

    // precalculate matrices for birdview transform if camera matrix and distortion coefficients are given
    if (mUndistEnable)
    {
      // Idea taken from http://stackoverflow.com/questions/29944709/how-to-combine-two-remap-operations-into-one
      cv::Mat optimalCameraMatrixInverse = cv::getOptimalNewCameraMatrix(mCameraMatrix, mDistCoeffs,
                                                                         mImgSize, 0).inv();
      cv::Mat warpMatrixInverse = mWarpMatrix.inv();
      cv::Mat_<float> productOptimalCameraMatrixInverseWithWarpMatrixInverse =
              optimalCameraMatrixInverse * warpMatrixInverse;


      cv::Mat undistortAndWarpXMapFloat(mImgSize, CV_32F);
      cv::Mat undistortAndWarpYMapFloat(mImgSize, CV_32F);

      for (int y = 0; y < mImgSize.height; ++y)
      {
        std::vector<cv::Point3f> pointsUndistortedNormalized(mImgSize.width);
        // For each pixel on the current row, first use the inverse perspective mapping, then multiply by the
        // inverse camera matrix (i.e. map from pixels to normalized coordinates to prepare use of projectPoints function)
        for (int x = 0; x < mImgSize.width; ++x)
        {
          cv::Mat_<float> pt(3, 1);
          pt << x, y, 1;
          pt = productOptimalCameraMatrixInverseWithWarpMatrixInverse * pt;
          pointsUndistortedNormalized[x].x = pt(0) / pt(2);
          pointsUndistortedNormalized[x].y = pt(1) / pt(2);
          pointsUndistortedNormalized[x].z = 1;
        }
        // For each pixel on the current row, compose with the inverse undistortion mapping (i.e. the distortion
        // mapping) using projectPoints function
        std::vector<cv::Point2f> pointsDistorted;
        cv::projectPoints(pointsUndistortedNormalized, cv::Mat::zeros(3, 1, CV_32F),
                          cv::Mat::zeros(3, 1, CV_32F), mCameraMatrix, mDistCoeffs,
                          pointsDistorted);
        // Store the result in the appropriate pixel of the output maps
        for (int x = 0; x < mImgSize.width; ++x)
        {
          undistortAndWarpXMapFloat.at<float>(y, x) = pointsDistorted[x].x;
          undistortAndWarpYMapFloat.at<float>(y, x) = pointsDistorted[x].y;
        }
      }
      // Finally, convert the float maps to signed-integer maps for best efficiency of the remap function
      cv::convertMaps(undistortAndWarpXMapFloat, undistortAndWarpYMapFloat, undistortAndWarpXMapInt,
                      undistortAndWarpYMapInt, CV_16SC2);
    }
  }
  else
  {
    LOGGING_ERROR(utilLogger, "can't open Calibration File" << endl);
    success = false;
  }
  fs2.release();
  return success;
}

std::vector<cv::Point2f> BirdViewConverter::transformPixels(const std::vector<cv::Point2f> imagePixels)
{
  if (mBirdviewScale != 1.0) {
    // We have to scale up the image pixels to the fullsized birdview and scale down the results afterwards
    std::vector<cv::Point2f> pixels;

    for (cv::Point2f pixel : imagePixels) {
      pixels.push_back(pixel / mBirdviewScale);
    }

    std::vector<cv::Point2f> birdViewPixels;
    cv::perspectiveTransform(pixels, birdViewPixels, mWarpMatrix);

    for (cv::Point2f& pixel : birdViewPixels) {
      pixel *= mBirdviewScale;
    }

    return birdViewPixels;

  } else {
    std::vector<cv::Point2f> birdViewPixels;
    cv::perspectiveTransform(imagePixels, birdViewPixels, mWarpMatrix);
    return birdViewPixels;

  }
}

cv::Mat BirdViewConverter::getDistortionCoefficients()
{
  return mDistCoeffs;
}

cv::Mat BirdViewConverter::getCameraMatrix()
{

  return mCameraMatrix;
}

}
}
